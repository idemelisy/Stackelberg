agents: 2
discount: 0.5
values: reward

states: 0 1 2 3 4
actions: 
0 1
0 1
observations:
0 1 2 3 4
0 1 2 3 4

start: 1.0 0.0 0.0 0.0 0.0

# Transition Dynamics
T: 0 0 : 0 : 4 : 1.0
T: 0 1 : 0 : 4 : 1.0
T: 1 0 : 0 : 1 : 1.0
T: 1 1 : 0 : 1 : 1.0

T: 0 0 : 1 : 4 : 1.0
T: 1 0 : 1 : 4 : 1.0
T: 0 1 : 1 : 2 : 1.0
T: 1 1 : 1 : 2 : 1.0

T: 0 0 : 2 : 4 : 1.0
T: 0 1 : 2 : 4 : 1.0
T: 1 0 : 2 : 3 : 1.0
T: 1 1 : 2 : 3 : 1.0

T: 1 0 : 3 : 4 : 1.0
T: 0 0 : 3 : 4 : 1.0
T: 1 1 : 3 : 4 : 1.0
T: 0 1 : 3 : 4 : 1.0

T: 0 0 : 4 : 4 : 1.0
T: 1 0 : 4 : 4 : 1.0
T: 0 1 : 4 : 4 : 1.0
T: 1 1 : 4 : 4 : 1.0

# Observations
O: 0 0 : 0 : 0 0 : 1.0
O: 0 0 : 1 : 1 1 : 1.0
O: 0 0 : 2 : 2 2 : 1.0
O: 0 0 : 3 : 3 3 : 1.0
O: 0 0 : 4 : 4 4 : 1.0

O: 0 1 : 0 : 0 0 : 1.0
O: 0 1 : 1 : 1 1 : 1.0
O: 0 1 : 2 : 2 2 : 1.0
O: 0 1 : 3 : 3 3 : 1.0
O: 0 1 : 4 : 4 4 : 1.0

O: 1 0 : 0 : 0 0 : 1.0
O: 1 0 : 1 : 1 1 : 1.0
O: 1 0 : 2 : 2 2 : 1.0
O: 1 0 : 3 : 3 3 : 1.0
O: 1 0 : 4 : 4 4 : 1.0

O: 1 1 : 0 : 0 0 : 1.0
O: 1 1 : 1 : 1 1 : 1.0
O: 1 1 : 2 : 2 2 : 1.0
O: 1 1 : 3 : 3 3 : 1.0
O: 1 1 : 4 : 4 4 : 1.0

# Rewards
R: 0 0 : 0 : * : * : 1 0
R: 0 1 : 0 : * : * : 1 0
R: 0 0 : 1 : * : * : 0 2
R: 1 0 : 1 : * : * : 0 2
R: 0 0 : 2 : * : * : 3 1
R: 0 1 : 2 : * : * : 3 1
R: 0 0 : 3 : * : * : 2 4
R: 1 0 : 3 : * : * : 2 4
R: 0 1 : 3 : * : * : 3 3
R: 1 1 : 3 : * : * : 3 3
R: 0 0 : 4 : * : * : 0 0
R: 0 1 : 4 : * : * : 0 0
R: 1 0 : 4 : * : * : 0 0
R: 1 1 : 4 : * : * : 0 0